

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>31. Methods of solution of MPD: RL &#8212; basics - math</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=5b4479735964841361fd" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=5b4479735964841361fd" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/exercise.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/style.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=5b4479735964841361fd" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd" />
  <script src="../../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=5b4479735964841361fd"></script>

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'ch/rl/mdp_sol_rl';</script>
    <link rel="shortcut icon" href="../../_static/favicon.svg"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="32. Large or Continuous MDPs" href="mdp_large_continuous.html" />
    <link rel="prev" title="30. Methods of solution of MPD: DP and LP" href="mdp_sol_dp_lp.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
<!-- Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-JPXX63Z3XR"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-JPXX63Z3XR');
</script>

  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/logo.svg" class="logo__image only-light" alt="basics - math - Home"/>
    <script>document.write(`<img src="../../_static/logo-dark.svg" class="logo__image only-dark" alt="basics - math - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Linear Algebra</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../linear-algebra/matrices.html">1. Matrices</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../linear-algebra/matrix-factorization.html">2. Matrix factorizations</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../linear-algebra/svd.html">2.3. Singular Value Decomposition</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../linear-algebra/linear-systems.html">3. Linear Systems</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Multivariable Calculus</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../multivariable/intro.html">4. Introduction to multi-variable calculus</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Differential Geometry</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../differential-geometry/intro.html">5. Introduction to Differential Geometry</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Vector and Tensor Algebra and Calculus</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../tensor-algebra-calculus/algebra.html">6. Tensor Algebra</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../tensor-algebra-calculus/calculus-euclidean.html">7. Tensor Calculus in Euclidean Spaces</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../tensor-algebra-calculus/calculus-euclidean-cartesian.html">7.5. Tensor Calculus in Euclidean Spaces - Cartesian coordinates in <span class="math notranslate nohighlight">\(E^3\)</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="../tensor-algebra-calculus/calculus-euclidean-cylindrical.html">7.6. Tensor Calculus in Euclidean Spaces - cylindrical coordinates in <span class="math notranslate nohighlight">\(E^3\)</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="../tensor-algebra-calculus/calculus-euclidean-spherical.html">7.7. Tensor Calculus in Euclidean Spaces - Spehrical coordinates in <span class="math notranslate nohighlight">\(E^3\)</span></a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../tensor-algebra-calculus/time-derivative-of-integrals.html">8. Time derivative of integrals over moving domains</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tensor-algebra-calculus/calculus-identities.html">9. Calculus identities</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Functional Analysis</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../functional-analysis/intro.html">10. Introduction to Functional Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../functional-analysis/dirac-delta.html">11. Dirac’s delta</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Complex Calculus</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../complex/analysis.html">12. Complex Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../complex/laplace.html">13. Laplace Transform</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../complex/fourier.html">14. Fourier Transforms</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../complex/fourier-series.html">14.1. Fourier Series</a></li>
<li class="toctree-l2"><a class="reference internal" href="../complex/fourier-transform.html">14.2. Fourier Transform</a></li>
<li class="toctree-l2"><a class="reference internal" href="../complex/fourier-transforms.html">14.3. Relations between Fourier transforms</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Calculus of Variations</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../calculus-variations/intro.html">15. Introduction to Calculus of Variations</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Ordinary Differential Equations</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../ode/intro.html">16. Introduction to Ordinary Differential Equations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ode/lti.html">17. Linear Time-Invariant Systems</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Partial Differential Equations</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../pde/intro.html">18. Introduction to Partial Differential Equations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pde/elliptic.html">19. Elliptic equations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pde/parabolic.html">20. Parabolic equations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pde/hyperbolic.html">21. Hyperbolic problems</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pde/nc.html">22. Navier-Cauchy equations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pde/ns.html">23. Navier-Stokes equations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pde/ale.html">24. Arbitrary Lagrangian-Eulerian description</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Numerical Methods for PDEs</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../pde/numerics.html">25. Introduction to numerical methods for PDEs</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../pde/fem.html">25.1. Finite Element Method</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pde/fvm.html">25.2. Finite Volume Method</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pde/bem.html">25.3. Boundary Element Method</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Boundary Methods for PDEs</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../pde/bem-poisson-helmholtz-waves.html">26. Green’s function method</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Optimization</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../optimization/intro.html">27. Optimization</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Reinforcement Learning</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="intro.html">28. Introduction to Reinforcement Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="mdp.html">29. Markov Processes</a></li>
<li class="toctree-l1"><a class="reference internal" href="mdp_sol_dp_lp.html">30. Methods of solution of MPD: DP and LP</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">31. Methods of solution of MPD: RL</a></li>
<li class="toctree-l1"><a class="reference internal" href="mdp_large_continuous.html">32. Large or Continuous MDPs</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/ch/rl/mdp_sol_rl.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Methods of solution of MPD: RL</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluation">31.1. Evaluation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#monte-carlo-rl">31.1.1. Monte-Carlo RL</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#temporal-difference-td-learning">31.1.2. Temporal Difference (TD) Learning</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#td-prediction">31.1.3. TD prediction</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-control">31.2. Model control</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#on-and-off-policy-learning">31.2.1. On- and Off-Policy Learning</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mc-control">31.2.2. MC control</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#varepsilon-greedy-policy-improvement">31.2.3. <span class="math notranslate nohighlight">\(\varepsilon\)</span>-greedy policy improvement</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#td-control">31.2.4. TD control</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#off-policy-learning">31.2.5. Off-policy learning</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#actor-critic">31.3. Actor-Critic</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#learning-and-planning">31.4. Learning and planning</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <div class="tex2jax_ignore mathjax_ignore section" id="methods-of-solution-of-mpd-rl">
<span id="rl-mdp-sol-rl"></span><h1><span class="section-number">31. </span>Methods of solution of MPD: RL<a class="headerlink" href="#methods-of-solution-of-mpd-rl" title="Permalink to this heading">#</a></h1>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
Introduction<div class="sd-summary-down docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-down" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M5.22 8.72a.75.75 0 000 1.06l6.25 6.25a.75.75 0 001.06 0l6.25-6.25a.75.75 0 00-1.06-1.06L12 14.44 6.28 8.72a.75.75 0 00-1.06 0z"></path></svg></div>
<div class="sd-summary-up docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-up" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M18.78 15.28a.75.75 0 000-1.06l-6.25-6.25a.75.75 0 00-1.06 0l-6.25 6.25a.75.75 0 101.06 1.06L12 9.56l5.72 5.72a.75.75 0 001.06 0z"></path></svg></div>
</summary><div class="sd-summary-content sd-card-body docutils">
<ul class="simple">
<li><p class="sd-card-text">model-free / model-based</p></li>
<li><p class="sd-card-text">on-policy / off-policy</p></li>
<li><p class="sd-card-text">online / offline</p></li>
<li><p class="sd-card-text">tabular / function approximation</p></li>
<li><p class="sd-card-text">value-based / policy-based / actor-critic</p></li>
</ul>
</div>
</details><p>Two main goals of methods in RL:</p>
<ul class="simple">
<li><p><a class="reference internal" href="#rl-mdp-sol-rl-eval"><span class="std std-ref">prediction or evaluation</span></a>: estimate the performance of a given policy</p></li>
<li><p><a class="reference internal" href="#rl-mdp-sol-rl-control"><span class="std std-ref">control</span></a>: find the best (or a good policy) to get the best performance</p></li>
</ul>
<p>These two tasks usually rely on two processes: <a class="reference internal" href="#rl-mdp-sol-rl-eval"><span class="std std-ref">evaluation</span></a> and <a class="reference internal" href="#rl-mdp-sol-rl-control-improv"><span class="std std-ref">improvement</span></a>. Evaluation stage provides the perfomance of a given policy usually in terms of value functions. Improvement aims at finding a new policy with better performance.</p>
<p>Prediction involves only the evaluation step, while control usually involves an iteration over alternate evaluation and improvement processes.</p>
<div class="section" id="evaluation">
<span id="rl-mdp-sol-rl-eval"></span><h2><span class="section-number">31.1. </span>Evaluation<a class="headerlink" href="#evaluation" title="Permalink to this heading">#</a></h2>
<div class="section" id="monte-carlo-rl">
<span id="rl-mdp-sol-rl-eval-mc"></span><h3><span class="section-number">31.1.1. </span>Monte-Carlo RL<a class="headerlink" href="#monte-carlo-rl" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>model-free, learn from experience of complete episodes ((-) no bootstrapping)</p></li>
<li><p>uses empirical mean return, instead of expected value</p></li>
<li><p>first-visit MC (unbiased estimator) / every-visit MC (biased estimator)</p></li>
</ul>
<p><strong>First-visit MC</strong></p>
<p>Initialize: <span class="math notranslate nohighlight">\(\pi\)</span> policy to be evaluated; <span class="math notranslate nohighlight">\(V\)</span> arbitrary state-value function, <span class="math notranslate nohighlight">\(R(s)\)</span> empty list of returns</p>
<p>Loop until convergence or stopping criterion</p>
<ul class="simple">
<li><p>generate an episode using <span class="math notranslate nohighlight">\(\pi\)</span></p>
<ul>
<li><p>for each state <span class="math notranslate nohighlight">\(s\)</span> in the episode:</p>
<ul>
<li><p>evalaute and append the return <span class="math notranslate nohighlight">\(r(s)\)</span> following the first occurrence of <span class="math notranslate nohighlight">\(s\)</span> to the list of <span class="math notranslate nohighlight">\(R(s)\)</span></p></li>
<li><p>update <span class="math notranslate nohighlight">\(V(s) = \text{average}(R(s))\)</span></p></li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>Every-visit MC</strong></p>
<p>Initialize: <span class="math notranslate nohighlight">\(\pi\)</span> policy to be evaluated; <span class="math notranslate nohighlight">\(V\)</span> arbitrary state-value function, <span class="math notranslate nohighlight">\(R(s)\)</span> empty list of returns</p>
<p>Loop until convergence or stopping criterion</p>
<ul class="simple">
<li><p>generate an episode using <span class="math notranslate nohighlight">\(\pi\)</span></p>
<ul>
<li><p>for each state <span class="math notranslate nohighlight">\(s\)</span> in the episode:</p>
<ul>
<li><p>for each occurrence of state <span class="math notranslate nohighlight">\(s\)</span> in the episode:</p>
<ul>
<li><p>evaluate and append the return <span class="math notranslate nohighlight">\(r(s)\)</span> following the occurrence of <span class="math notranslate nohighlight">\(s\)</span> to the list of <span class="math notranslate nohighlight">\(R(s)\)</span></p></li>
<li><p>update <span class="math notranslate nohighlight">\(V(s) = \text{average}(R(s))\)</span></p></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>Using incremental mean update</strong></p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
  \mu_{N+1} 
  &amp; = \frac{x_1 + \dots + x_N + x_{N+1}}{N+1} = \\
  &amp; = \frac{x_1 + \dots + x_N}{N} \frac{N}{N+1} + \frac{x_{N+1}}{N+1} = \\
  &amp; = \frac{N}{N+1} \mu_{N} + \frac{1}{N+1} x_{N+1} = \\
  &amp; = \mu_{N} + \frac{1}{N+1} \left( x_{N+1} - \mu_{N} \right)
\end{aligned}\end{split}\]</div>
<p>Incremental update of the average of the value function reads</p>
<div class="math notranslate nohighlight">
\[V_{k}(s) \leftarrow V_{k-1}(s) + \frac{1}{k} \left( v_k - V_{k-1}(s) \right) \ ,\]</div>
<p>with <span class="math notranslate nohighlight">\(v_k\)</span> the return of state <span class="math notranslate nohighlight">\(s_k\)</span>.</p>
<p>A generalized update may follow, to introduce a free hyperparameter as a weight of older estimation,</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
  V_{k}(s) 
  \leftarrow &amp; \ V_{k-1}(s) + \alpha_k \left( v_k - V_{k-1}(s) \right) \\
           = &amp; \ ( 1 - \alpha_k ) V_{k-1}(s) + \alpha_k v_k
\end{aligned}\end{split}\]</div>
</div>
<div class="section" id="temporal-difference-td-learning">
<span id="rl-mdp-sol-rl-eval-td"></span><h3><span class="section-number">31.1.2. </span>Temporal Difference (TD) Learning<a class="headerlink" href="#temporal-difference-td-learning" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>model-free, learn from experience of incomplete episodes (bootstrapping)</p></li>
<li><p>…</p></li>
</ul>
</div>
<div class="section" id="td-prediction">
<h3><span class="section-number">31.1.3. </span>TD prediction<a class="headerlink" href="#td-prediction" title="Permalink to this heading">#</a></h3>
<ul>
<li><p>Starting from every visit MC</p>
<div class="math notranslate nohighlight">
\[V(s_t) \leftarrow V(s_t) + \alpha (v_t - V(s_t))\]</div>
</li>
<li><p>Update towards an <strong>estimation of the return</strong></p>
<ul>
<li><p>the simplest TD algorithm is <span class="math notranslate nohighlight">\(TD(0)\)</span>.</p>
<ul>
<li><p>estimated return (called <strong>TD target</strong>) reads</p>
<div class="math notranslate nohighlight">
\[v_t \sim r_{t+1} + \gamma V(s_{t+1}) \]</div>
</li>
<li><p><strong>TD error</strong> error <span class="math notranslate nohighlight">\(\delta_t\)</span> is defined as</p>
<div class="math notranslate nohighlight">
\[\delta_t := r_{t+1} + \gamma V(s_{t+1}) - V(s_t)\]</div>
</li>
<li><p>update step</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
         V(s)
         \leftarrow &amp; \ V(s) + \alpha_k \left( r_{t+1} + \gamma V(s_{t+1}) - V(s_{t+1}) \right) = \\
                  = &amp; \ V(s) + \alpha_k \, \delta_t
       \end{aligned}\end{split}\]</div>
</li>
</ul>
</li>
<li><p><span class="math notranslate nohighlight">\(TD(n)\)</span> algorithm uses <span class="math notranslate nohighlight">\(n\)</span>-step prediction</p>
<div class="math notranslate nohighlight">
\[v_t^{(n)} = r_{t+1} + \gamma r_{t+2} + \dots \gamma r_{t+n} + \gamma^{n+1} V(s_{t+n})\]</div>
</li>
<li><p><span class="math notranslate nohighlight">\(\lambda\)</span>-return <span class="math notranslate nohighlight">\(v_t^\lambda\)</span> combines all <span class="math notranslate nohighlight">\(n\)</span>-step returns <span class="math notranslate nohighlight">\(v^{(n)}_t\)</span> as</p>
<div class="math notranslate nohighlight">
\[v_t^{\lambda} := (1-\lambda) \sum_{n=1}^{+\infty} \lambda^{n-1} v_t^{(n)}\]</div>
<p>weights s.t. sum of weights <span class="math notranslate nohighlight">\(=1\)</span> and decay as <span class="math notranslate nohighlight">\(\lambda ( &lt; 1)\)</span></p>
</li>
<li><p>…eligibility traces, forward and backward TD,…</p></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="section" id="model-control">
<span id="rl-mdp-sol-rl-control"></span><h2><span class="section-number">31.2. </span>Model control<a class="headerlink" href="#model-control" title="Permalink to this heading">#</a></h2>
<div class="section" id="on-and-off-policy-learning">
<span id="rl-mdp-sol-rl-control-improv"></span><h3><span class="section-number">31.2.1. </span>On- and Off-Policy Learning<a class="headerlink" href="#on-and-off-policy-learning" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>On-policy: learn policy <span class="math notranslate nohighlight">\(\pi\)</span> from experience sampled from <span class="math notranslate nohighlight">\(\pi\)</span></p></li>
<li><p>Off-policy: learn policy <span class="math notranslate nohighlight">\(\pi\)</span> from experience sampled from <span class="math notranslate nohighlight">\(\widetilde{\pi}\)</span></p></li>
</ul>
<p><strong>Greedy policy improvement</strong></p>
<ul>
<li><p>over <span class="math notranslate nohighlight">\(V(s)\)</span> requires model of MDP,</p>
<div class="math notranslate nohighlight">
\[\pi'(s) = \text{argmax}_{a \in A} \left\{ R(s,a) + P(s'|s,a) V(s') \right\} \]</div>
</li>
<li><p><strong>over <span class="math notranslate nohighlight">\(Q(s,a)\)</span> is model-free</strong></p>
<div class="math notranslate nohighlight">
\[\pi'(s) = \text{argmax}_{a \in A} Q(s,a) \ .\]</div>
</li>
</ul>
</div>
<div class="section" id="mc-control">
<span id="rl-mdp-sol-rl-control-mc"></span><h3><span class="section-number">31.2.2. </span>MC control<a class="headerlink" href="#mc-control" title="Permalink to this heading">#</a></h3>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Generalized policy iteration with MC evaluation</p>
<p>MC evaluation is model-free. To keep a model-free control task, a model-free policy improvement is required, like greedy policy improvement over <span class="math notranslate nohighlight">\(Q(s,a)\)</span>.</p>
</div>
</div>
<div class="section" id="varepsilon-greedy-policy-improvement">
<span id="rl-mdp-sol-rl-control-improv-eps-greedy"></span><h3><span class="section-number">31.2.3. </span><span class="math notranslate nohighlight">\(\varepsilon\)</span>-greedy policy improvement<a class="headerlink" href="#varepsilon-greedy-policy-improvement" title="Permalink to this heading">#</a></h3>
<div class="math notranslate nohighlight">
\[\begin{split}
\pi(a|s) = \left\{
\begin{aligned}
  &amp; 1 - \varepsilon \left( 1 - \frac{1}{N} \right) &amp;&amp; , \qquad  \text{if } a = \text{argmax}_{a \in A} Q^{\pi}(s,a) \\
  &amp; \frac{\varepsilon}{N} &amp;&amp; , \qquad \text{otherwise}
\end{aligned}
\right.
\end{split}\]</div>
<div class="proof theorem admonition" id="theorem-0">
<p class="admonition-title"><span class="caption-number">Theorem 31.1 </span> (<span class="math notranslate nohighlight">\(\varepsilon\)</span>-greedy Policy Improvement)</p>
<div class="theorem-content section" id="proof-content">
<p>For …, the <span class="math notranslate nohighlight">\(\varepsilon\)</span>-greedy policy <span class="math notranslate nohighlight">\(\pi'\)</span> w.r.t. <span class="math notranslate nohighlight">\(Q^{\pi}\)</span> is an improvement, <span class="math notranslate nohighlight">\(V^{\pi'}(s) \ge V^{\pi}(s)\)</span>.</p>
</div>
</div><details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
Proof<div class="sd-summary-down docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-down" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M5.22 8.72a.75.75 0 000 1.06l6.25 6.25a.75.75 0 001.06 0l6.25-6.25a.75.75 0 00-1.06-1.06L12 14.44 6.28 8.72a.75.75 0 00-1.06 0z"></path></svg></div>
<div class="sd-summary-up docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-up" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M18.78 15.28a.75.75 0 000-1.06l-6.25-6.25a.75.75 0 00-1.06 0l-6.25 6.25a.75.75 0 101.06 1.06L12 9.56l5.72 5.72a.75.75 0 001.06 0z"></path></svg></div>
</summary><div class="sd-summary-content sd-card-body docutils">
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
  Q^{\pi}(s, \pi'(s))
  &amp; = \sum_{a \in A} \pi'(a|s) Q^{\pi}(s,a) = \\
  &amp; = \sum_{a \in A, a \ne a^*} \frac{\varepsilon}{m} Q^{\pi}(s,a) + \left( 1 - \varepsilon + \frac{\varepsilon}{m} \right) Q^{\pi}(s,a^*) = \\
  &amp; = \sum_{a \in A} \frac{\varepsilon}{m} Q^{\pi}(s,a) + \left( 1 - \varepsilon \right) Q^{\pi}(s,a^*) = \\
  (1) &amp; \ge \sum_{a \in A} \frac{\varepsilon}{m} Q^{\pi}(s,a) + \left( 1 - \varepsilon \right) \sum_{a \in A} \dfrac{\pi(a|s) - \frac{\varepsilon}{m}}{1 - \varepsilon} Q^{\pi}(s,a) = \\
  &amp; = \sum_{a \in A} \pi(a|s) Q^{\pi}(s,a) = V^{\pi}(s) \\
\end{aligned}\end{split}\]</div>
<p class="sd-card-text">having used in <span class="math notranslate nohighlight">\((1)\)</span> …
And for the policy improvement theorem <a class="reference internal" href="mdp_sol_dp_lp.html#thm:pi">Theorem 30.1</a>, <span class="math notranslate nohighlight">\(V^{\pi'}(s) \ge V(s)\)</span>. <strong>todo</strong> <em>Check it!</em></p>
</div>
</details><p><strong>GLIE (Greedy in the Limit of Infinite Exploration)</strong> …</p>
<p><strong>GLIE MC Control</strong></p>
<ul>
<li><p><span class="math notranslate nohighlight">\(k^{th}\)</span> episode using \pi$$</p></li>
<li><p>for each state <span class="math notranslate nohighlight">\(s_t\)</span>,  and action <span class="math notranslate nohighlight">\(a_t\)</span> in the episode, update number of <span class="math notranslate nohighlight">\((s,a)\)</span> pair occurence and action-value function</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
     N(s_t, a_t) &amp; \ \leftarrow \ N(s_t, a_t) + 1 \\
     Q(s_t, a_t) &amp; \ \leftarrow \ Q(s_t, a_t) + \frac{1}{N(s_t, a_t)} (v_t - Q(s_t, a_t))
   \end{aligned}\end{split}\]</div>
</li>
<li><p>improve policy with <span class="math notranslate nohighlight">\(\varepsilon\)</span>-greedy method over action-value function <span class="math notranslate nohighlight">\(Q\)</span>,</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
    \varepsilon &amp; \ \leftarrow \ \frac{1}{k} \\
    \pi &amp; \ \leftarrow \ \varepsilon-\text{greedy}(Q) \\
  \end{aligned}\end{split}\]</div>
</li>
</ul>
</div>
<div class="section" id="td-control">
<span id="rl-mdp-sol-rl-control-td"></span><h3><span class="section-number">31.2.4. </span>TD control<a class="headerlink" href="#td-control" title="Permalink to this heading">#</a></h3>
<ul>
<li><p>(+): online, from incomplete episodes, lower variance</p></li>
<li><p>use TD instead of MC for policy evaluation, <strong>SARSA</strong>:</p>
<div class="math notranslate nohighlight">
\[Q(s,a) \ \leftarrow \ Q(s,a) + \alpha \left( r + \gamma Q(s',a') - Q(s,a) \right)\]</div>
</li>
</ul>
<p>…</p>
<p><strong>Variations.</strong> SARSA<span class="math notranslate nohighlight">\((\lambda)\)</span>,…</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>SARSA is on-policy</p>
</div>
</div>
<div class="section" id="off-policy-learning">
<h3><span class="section-number">31.2.5. </span>Off-policy learning<a class="headerlink" href="#off-policy-learning" title="Permalink to this heading">#</a></h3>
<p><strong>Q-learning</strong>, is off-policy as <span class="math notranslate nohighlight">\(a'\)</span> is not taken from <span class="math notranslate nohighlight">\(\pi\)</span></p>
<div class="math notranslate nohighlight">
\[Q(s,a) \ \leftarrow \ Q(s,a) + \alpha \left( r + \gamma \max_{a'} Q(s',a') - Q(s,a) \right)\]</div>
</div>
</div>
<div class="section" id="actor-critic">
<span id="rl-mdp-sol-rl-ac"></span><h2><span class="section-number">31.3. </span>Actor-Critic<a class="headerlink" href="#actor-critic" title="Permalink to this heading">#</a></h2>
<p><strong>todo</strong></p>
</div>
<div class="section" id="learning-and-planning">
<h2><span class="section-number">31.4. </span>Learning and planning<a class="headerlink" href="#learning-and-planning" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Model-free RL: no model; <strong>learn</strong> policy and/or value function from real experience</p></li>
<li><p>Model-based RL: learn a model from real experience; <strong>plan</strong> policy and/or value function from simulated experience</p></li>
<li><p>Dyna: leanr a model from real experience; <strong>learn and plan</strong> a policy and/or value function from real and simulated experience</p></li>
</ul>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./ch/rl"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="mdp_sol_dp_lp.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">30. </span>Methods of solution of MPD: DP and LP</p>
      </div>
    </a>
    <a class="right-next"
       href="mdp_large_continuous.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">32. </span>Large or Continuous MDPs</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluation">31.1. Evaluation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#monte-carlo-rl">31.1.1. Monte-Carlo RL</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#temporal-difference-td-learning">31.1.2. Temporal Difference (TD) Learning</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#td-prediction">31.1.3. TD prediction</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-control">31.2. Model control</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#on-and-off-policy-learning">31.2.1. On- and Off-Policy Learning</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mc-control">31.2.2. MC control</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#varepsilon-greedy-policy-improvement">31.2.3. <span class="math notranslate nohighlight">\(\varepsilon\)</span>-greedy policy improvement</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#td-control">31.2.4. TD control</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#off-policy-learning">31.2.5. Off-policy learning</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#actor-critic">31.3. Actor-Critic</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#learning-and-planning">31.4. Learning and planning</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By basics
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=5b4479735964841361fd"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>